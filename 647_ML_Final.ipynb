{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#import statements\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#load dataset into dataframe\ndf = pd.read_csv('MLTEST_clean.csv')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#convert benign/bot class labels into numeric values\nNewLabel = []\nfor i in df[\"Label\"]:\n    if i ==\"BENIGN\":\n        NewLabel.append(0)\n    else:\n        NewLabel.append(1)\ndf[\"Label\"]=NewLabel",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#assign feature matrix (x) and response vector (y)\ny = df['Label'].values\ndel df['Label']\nx = df.values",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#transform feature matrix (x) to map original values to a more uniform distribution\nscaler = QuantileTransformer(n_quantiles=1000, random_state=42)\nscaled_df = scaler.fit_transform(x)\nx = pd.DataFrame(scaled_df)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#split data into train and test set\nxTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 42)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#begin individual classifier training and evaluation\n#AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=50, learning_rate=1)\nada.fit(xTrain,yTrain)\nyPred = ada.predict(xTest)\nprint(\"AdaBoostClassifier Performance Metrics\")\nprint(\"Accuracy Score: \", accuracy_score(yTest,yPred))\nprint(\"Precision Score: \", precision_score(yTest,yPred))\nprint(\"Recall Score: \", recall_score(yTest,yPred))\nprint(\"F1 Score: \", f1_score(yTest,yPred))\ntn, fp, fn, tp = confusion_matrix(yTest, yPred).ravel()\nfpr = (fp / (fp + tn)) * 100\nprint(\"False Positive Rate: \" +str(fpr))\nprint(\"AdaBoostClassifier Confusion Matrix:\")\nprint(\"True Positives: \" +str(tp))\nprint(\"False Positives: \" +str(fp))\nprint(\"True Negatives: \" +str(tn))\nprint(\"False Negatives: \" +str(fn))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "AdaBoostClassifier Performance Metrics\nAccuracy Score:  0.9997119136788624\nPrecision Score:  0.9856801909307876\nRecall Score:  0.9880382775119617\nF1 Score:  0.986857825567503\nFalse Positive Rate: 0.015887726731100223\nAdaBoostClassifier Confusion Matrix:\nTrue Positives: 413\nFalse Positives: 6\nTrue Negatives: 37759\nFalse Negatives: 5\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#CART\ncart = DecisionTreeClassifier()\ncart.fit(xTrain,yTrain)\nyPred = cart.predict(xTest)\nprint(\"DecisionTreeClassifier Performance Metrics\")\nprint(\"Accuracy Score: \", accuracy_score(yTest,yPred))\nprint(\"Precision Score: \", precision_score(yTest,yPred))\nprint(\"Recall Score: \", recall_score(yTest,yPred))\nprint(\"F1 Score: \", f1_score(yTest,yPred))\ntn, fp, fn, tp = confusion_matrix(yTest, yPred).ravel()\nfpr = (fp / (fp + tn)) * 100\nprint(\"False Positive Rate: \" +str(fpr))\nprint(\"DecisionTreeClassifier Confusion Matrix:\")\nprint(\"True Positives: \" +str(tp))\nprint(\"False Positives: \" +str(fp))\nprint(\"True Negatives: \" +str(tn))\nprint(\"False Negatives: \" +str(fn))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "DecisionTreeClassifier Performance Metrics\nAccuracy Score:  0.9997642930099783\nPrecision Score:  0.9857482185273159\nRecall Score:  0.992822966507177\nF1 Score:  0.9892729439809297\nFalse Positive Rate: 0.015887726731100223\nDecisionTreeClassifier Confusion Matrix:\nTrue Positives: 415\nFalse Positives: 6\nTrue Negatives: 37759\nFalse Negatives: 3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Naive Bayes\nnb = GaussianNB()\nnb.fit(xTrain, yTrain)\nyPred = nb.predict(xTest)\nprint(\"Naive Bayes Performance Metrics\")\nprint(\"Accuracy Score: \", accuracy_score(yTest,yPred))\nprint(\"Precision Score: \", precision_score(yTest,yPred))\nprint(\"Recall Score: \", recall_score(yTest,yPred))\nprint(\"F1 Score: \", f1_score(yTest,yPred))\ntn, fp, fn, tp = confusion_matrix(yTest, yPred).ravel()\nfpr = (fp / (fp + tn)) * 100\nprint(\"False Positive Rate: \" +str(fpr))\nprint(\"Naive Bayes Confusion Matrix:\")\nprint(\"True Positives: \" +str(tp))\nprint(\"False Positives: \" +str(fp))\nprint(\"True Negatives: \" +str(tn))\nprint(\"False Negatives: \" +str(fn))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Naive Bayes Performance Metrics\nAccuracy Score:  0.6875049105622921\nPrecision Score:  0.033846153846153845\nRecall Score:  1.0\nF1 Score:  0.06547619047619048\nFalse Positive Rate: 31.59539255924798\nNaive Bayes Confusion Matrix:\nTrue Positives: 418\nFalse Positives: 11932\nTrue Negatives: 25833\nFalse Negatives: 0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(xTrain, yTrain) \nyPred = neigh.predict(xTest)\nprint(\"KNN Performance Metrics\")\nprint(\"Accuracy Score: \", accuracy_score(yTest,yPred))\nprint(\"Precision Score: \", precision_score(yTest,yPred))\nprint(\"Recall Score: \", recall_score(yTest,yPred))\nprint(\"F1 Score: \", f1_score(yTest,yPred))\ntn, fp, fn, tp = confusion_matrix(yTest, yPred).ravel()\nfpr = (fp / (fp + tn)) * 100\nprint(\"False Positive Rate: \" +str(fpr))\nprint(\"KNN Confusion Matrix:\")\nprint(\"True Positives: \" +str(tp))\nprint(\"False Positives: \" +str(fp))\nprint(\"True Negatives: \" +str(tn))\nprint(\"False Negatives: \" +str(fn))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "KNN Performance Metrics\nAccuracy Score:  0.9992143100332609\nPrecision Score:  0.9597156398104265\nRecall Score:  0.9688995215311005\nF1 Score:  0.9642857142857143\nFalse Positive Rate: 0.04501522573811731\nKNN Confusion Matrix:\nTrue Positives: 405\nFalse Positives: 17\nTrue Negatives: 37748\nFalse Negatives: 13\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=None)\nrf.fit(xTrain, yTrain)\nyPred = rf.predict(xTest)\nprint(\"Random Forest Performance Metrics\")\nprint(\"Accuracy Score: \", accuracy_score(yTest,yPred))\nprint(\"Precision Score: \", precision_score(yTest,yPred))\nprint(\"Recall Score: \", recall_score(yTest,yPred))\nprint(\"F1 Score: \", f1_score(yTest,yPred))\ntn, fp, fn, tp = confusion_matrix(yTest, yPred).ravel()\nfpr = (fp / (fp + tn)) * 100\nprint(\"False Positive Rate: \" +str(fpr))\nprint(\"Random Forest Confusion Matrix:\")\nprint(\"True Positives: \" +str(tp))\nprint(\"False Positives: \" +str(fp))\nprint(\"True Negatives: \" +str(tn))\nprint(\"False Negatives: \" +str(fn))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Random Forest Performance Metrics\nAccuracy Score:  0.9996857240133044\nPrecision Score:  1.0\nRecall Score:  0.9712918660287081\nF1 Score:  0.9854368932038834\nFalse Positive Rate: 0.0\nRandom Forest Confusion Matrix:\nTrue Positives: 406\nFalse Positives: 0\nTrue Negatives: 37765\nFalse Negatives: 12\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}